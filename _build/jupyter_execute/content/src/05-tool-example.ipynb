{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "pseudo code for what we want (taken from <https://huggingface.co/docs/smolagents/v1.3.0/en/conceptual_guides/intro_agents>)\n",
    "\n",
    "```\n",
    "memory = [user_defined_task]\n",
    "while llm_should_continue(memory): # this loop is the multi-step part\n",
    "    action = llm_get_next_action(memory) # this is the tool-calling part\n",
    "    observations = execute_action(action)\n",
    "    memory += [action, observations]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Models, get_models, load_model\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_3_2_3b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.models import Models, get_models, load_model\n",
    "\n",
    "model = load_model(\"llama_3_2_3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selenium web driver\n",
    "we use this to control the agents' online presence :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from pydantic import BaseModel, Field, Json\n",
    "from typing import List, Any\n",
    "\n",
    "\n",
    "class Agent(ABC):\n",
    "    @abstractmethod\n",
    "    def system(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def prompt(self, *args, **kwargs) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def schema(self, *args, **kwargs) -> dict[str, Any]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESG data sentence classification AND (dataset OR data sources) AND (text OR natural language processing OR NLP) AND (machine learning OR deep learning) AND (environmental OR social OR governance) AND (dataset OR data sources OR data repository)\n"
     ]
    }
   ],
   "source": [
    "from src.generate import generate\n",
    "\n",
    "# tools = [\n",
    "#     \"search_engine\",\n",
    "#     \"dataset_generator\"\n",
    "# ]\n",
    "# tools_str = \", \".join(f\"{i+1}. {tool}\" for i, tool in enumerate(tools))\n",
    "\n",
    "# main_system = f\"You are an intelligent assistant that helps the user in the necessary steps required to generate a dataset. Based on the users input, you should create tasks as described by the  {len(tools)} tools you have available: {tools_str}.\"\n",
    "# print(main_system)\n",
    "\n",
    "\n",
    "class SearchAgent(Agent):\n",
    "    def system(self):\n",
    "        return \"You are tasked with reformulating a topic into a boolean AND/OR search string suitable for search engines. Maximum 3 operations. It MUST include 'dataset' or 'data sources'. Output in JSON according to the provided schema.\"\n",
    "    \n",
    "    def prompt(self, topic: str):\n",
    "        return f\"Generate a Google keyword search that will help the user find datasets on the topic of {topic}. Do not constrain the search to specific sites. Use your knowledge of the topic to generate a comprehensive search string.\"\n",
    "    \n",
    "    def schema(self):\n",
    "        class SearchSchema(BaseModel):\n",
    "            search: str\n",
    "        return SearchSchema.model_json_schema()\n",
    "    \n",
    "    def __call__(self, topic: str):\n",
    "        return generate(\n",
    "            system_prompt=self.system(),\n",
    "            prompt=self.prompt(topic),\n",
    "            schema=self.schema(),\n",
    "            model=model,\n",
    "            num_ctx=1000,\n",
    "            num_predict=200,\n",
    "            temperature=0.0\n",
    "        )[\"search\"]\n",
    "\n",
    "\n",
    "TOPIC = \"ESG-based data for sentence-level classification\"\n",
    "search_agent = SearchAgent()\n",
    "\n",
    "search_string = search_agent(topic=TOPIC)\n",
    "print(search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "from markitdown import MarkItDown\n",
    "\n",
    "# ddgs = DDGS(proxy=\"tb\", timeout=20) \n",
    "# this requires the TOR browser to be installed and running for a proxy\n",
    "# should be used if you plan on querying a lot.\n",
    "ddgs = DDGS(timeout=20) \n",
    "# prepare the markdown extractor\n",
    "md = MarkItDown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://huggingface.co/nbroad/ESG-BERT',\n",
       " 'https://www.sofi.com/learn/content/esg-score/',\n",
       " 'https://open-research-europe.ec.europa.eu/articles/5-28']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_urls(search_string: str, max_results: int = 3):\n",
    "    res = ddgs.text(search_string, max_results=max_results, region=\"us-en\", safesearch=\"on\")\n",
    "    hrefs = [r[\"href\"] for r in res]\n",
    "    return hrefs\n",
    "\n",
    "urls = get_urls(search_string)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "LANGUAGE = \"English\"\n",
    "search_for_dataset_info_query = \"From the provided markdown text:\\n{MARKDOWN}\\nFind direct links to datasets, descriptions of datasets, and other information that explains something about the data. The dataset should be in {LANGUAGE}.\"\n",
    "\n",
    "def visit_site(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    html = driver.page_source\n",
    "    return html\n",
    "\n",
    "TMP_FOLDER = \"tmp-markdown\"\n",
    "shutil.rmtree(TMP_FOLDER, ignore_errors=True)\n",
    "for uid, url in enumerate(urls):\n",
    "    html = visit_site(url)\n",
    "\n",
    "    TMP = \"tmp.html\"\n",
    "    with open(TMP, \"w\") as f:\n",
    "        f.write(html)\n",
    "    result = md.convert(TMP)\n",
    "\n",
    "    # to deal with large contexts, split by headlines\n",
    "    hashed_results = result.text_content.split(\"\\n#\")\n",
    "    hashed_results = [h.strip() for h in hashed_results if len(h.strip().split(\"\\n\")) > 1]\n",
    "\n",
    "    MAX_RESULTS = 100\n",
    "    if len(hashed_results) > MAX_RESULTS:\n",
    "        hashed_results = hashed_results[:MAX_RESULTS]\n",
    "\n",
    "    os.makedirs(TMP_FOLDER, exist_ok=True)\n",
    "\n",
    "    # we store the markdown unique to each URL in the current session:\n",
    "    for i, hashed_result in enumerate(hashed_results):\n",
    "        with open(f\"tmp-markdown/{uid}_{i}.md\", \"w\") as f:\n",
    "            f.write(hashed_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a2556b474e4290a3cfd42cde47741c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing URLs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2e52cc0add4dcebc925e40571fdf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing URL 0 (https://huggingface.co/nbroad/ESG-BERT):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to parse response: {\n",
      "  \"datasets\": []\n",
      "}\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da60a64441b7431799d5391cd1583c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing URL 1 (https://www.sofi.com/learn/content/esg-score/):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to parse response: {\n",
      "  \"datasets\": []\n",
      "}\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28455c408b842d3bd02f1b4cfd500e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing URL 2 (https://open-research-europe.ec.europa.eu/articles/5-28):   0%|          | 0/34 [00:00<?, ?iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to parse response: {\n",
      "  \"datasets\": []\n",
      "}\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from pydantic.json_schema import GenerateJsonSchema, JsonSchemaValue\n",
    "from typing import Literal\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "LANGUAGE = \"English\"\n",
    "\n",
    "class DatasetAgent(Agent):\n",
    "    def system(self):\n",
    "        return f\"You are a helpful assistant that extracts information about datasets about {TOPIC}.\"\n",
    "\n",
    "    def prompt(self, markdown_file_path):\n",
    "        data = None\n",
    "        with open(markdown_file_path) as f:\n",
    "            data = f.read()\n",
    "        if not data:\n",
    "            return \"No data provided.\"\n",
    "        return f\"From the provided information:\\n{data}\\nFind details about specific datasets (in {LANGUAGE} preferably), including information about its language, links, and labels. Determine if the dataset is relevant to the topic of {TOPIC} and is in the {LANGUAGE} language, specified by the 'relevant' field. Output in JSON.\"\n",
    "\n",
    "    def schema(self):\n",
    "        class DatasetLabel(BaseModel):\n",
    "            label: str = Field(\n",
    "                title=\"Label or category\",\n",
    "                description=\"The label of the dataset, such as the name of a category.\"\n",
    "            )\n",
    "\n",
    "        class DatasetSchema(BaseModel):\n",
    "            name: str\n",
    "            language: str\n",
    "            labels: List[DatasetLabel]\n",
    "            relevant: Literal[\"yes\", \"no\"]\n",
    "\n",
    "        class DatasetFinderSchema(BaseModel):\n",
    "            datasets: List[DatasetSchema]\n",
    "\n",
    "        return DatasetFinderSchema.model_json_schema()\n",
    "\n",
    "    def __call__(self, markdown_file_path: str, output_key: str = \"datasets\"):\n",
    "        output = generate(\n",
    "            system_prompt=self.system(),\n",
    "            prompt=self.prompt(markdown_file_path=markdown_file_path),\n",
    "            schema=self.schema(),\n",
    "            model=model,\n",
    "            # num_ctx=1000,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        if output:\n",
    "            return output[output_key]\n",
    "        return None\n",
    "\n",
    "dataset_agent = DatasetAgent()\n",
    "\n",
    "filtered_datasets = []\n",
    "\n",
    "outer_iterator = tqdm(urls, desc=\"Processing URLs\", leave=False)\n",
    "for uid, url in enumerate(outer_iterator):\n",
    "    data_path = os.path.join(TMP_FOLDER, f\"{uid}_{i}.md\")\n",
    "    data_paths = sorted(os.listdir(TMP_FOLDER))\n",
    "    \n",
    "    iterator = tqdm(data_paths, desc=f\"Processing URL {uid} ({url})\")\n",
    "    for data_path in iterator:\n",
    "        md_file = os.path.join(TMP_FOLDER, data_path)\n",
    "        datasets = dataset_agent(markdown_file_path=md_file)\n",
    "        if not datasets:\n",
    "            continue\n",
    "        for dataset in datasets:\n",
    "            if dataset[\"relevant\"] == \"yes\":\n",
    "                filtered_datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contrast',\n",
       " 'entailment',\n",
       " 'esg rating: high',\n",
       " 'esg rating: low',\n",
       " 'esg rating: medium',\n",
       " 'esg score: high',\n",
       " 'esg score: low',\n",
       " 'esg score: medium',\n",
       " 'esg-related news',\n",
       " 'high csr',\n",
       " 'low csr',\n",
       " 'masked language modelling',\n",
       " 'negative',\n",
       " 'negative esg',\n",
       " 'negative esg sentiment',\n",
       " 'negative esg statement',\n",
       " 'neutral',\n",
       " 'neutral esg sentiment',\n",
       " 'neutral esg statement',\n",
       " 'next sentence prediction',\n",
       " 'non-esg related news',\n",
       " 'non-sustainable',\n",
       " 'positive',\n",
       " 'positive esg',\n",
       " 'positive esg sentiment',\n",
       " 'positive esg statement',\n",
       " 'relevant',\n",
       " 'strong csr performance',\n",
       " 'sustainable',\n",
       " 'text classification',\n",
       " 'very negative',\n",
       " 'very positive',\n",
       " 'weak csr performance'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_labels = set()\n",
    "for dataset in filtered_datasets:\n",
    "    for label in dataset[\"labels\"]:\n",
    "        filtered_labels.add(label[\"label\"].lower())\n",
    "\n",
    "filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label_name': 'ESG Sentiment',\n",
       "  'description': 'Sentiment classification of ESG-related text',\n",
       "  'possible_values': ['positive', 'negative', 'neutral']},\n",
       " {'label_name': 'CSR Performance',\n",
       "  'description': 'Classification of CSR performance',\n",
       "  'possible_values': ['strong', 'weak', 'low', 'high']},\n",
       " {'label_name': 'ESG Rating',\n",
       "  'description': 'Classification of ESG rating',\n",
       "  'possible_values': ['low', 'medium', 'high']},\n",
       " {'label_name': 'ESG Topic',\n",
       "  'description': 'Classification of ESG topic',\n",
       "  'possible_values': ['sustainable', 'non-sustainable']}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class LabelerAgent(Agent):\n",
    "    def system(self):\n",
    "        return f\"You are an assistant that labels datasets based on the topic of {TOPIC}.\"\n",
    "\n",
    "    def prompt(self, labels: List[str], num_labels: int):\n",
    "        labels_str = \", \".join(labels)\n",
    "        return f\"From the provided list of previously found labels from datasets on {TOPIC}: {labels_str}\\nCreate a list of {num_labels} label categories. Determine the name and type for each label. Output in JSON.\"\n",
    "\n",
    "    def schema(self):\n",
    "        class DatasetLabel(BaseModel):\n",
    "            label_name: str\n",
    "            description: str\n",
    "            possible_values: List[str]\n",
    "\n",
    "        class LabelerSchema(BaseModel):\n",
    "            labels: List[DatasetLabel]\n",
    "\n",
    "        return LabelerSchema.model_json_schema()\n",
    "    \n",
    "    def __call__(self, labels: List[str], num_labels: int, output_key: str = \"labels\"):\n",
    "        output = generate(\n",
    "            system_prompt=self.system(),\n",
    "            prompt=self.prompt(labels, num_labels),\n",
    "            schema=self.schema(),\n",
    "            model=model,\n",
    "            num_ctx=4000,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        if output:\n",
    "            return output[output_key]\n",
    "\n",
    "        \n",
    "labeler_agent = LabelerAgent()\n",
    "labels = list(filtered_labels)\n",
    "labels = labeler_agent(labels=labels, num_labels=4)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_labels(labels: List[dict[str, str]]) -> str:\n",
    "    sb = []\n",
    "    for l in labels:\n",
    "        sb.append(f\"{l['label_name']}: {l['description']}\")\n",
    "        sb.append(\"Possible values:\")\n",
    "        for v in l[\"possible_values\"]:\n",
    "            sb.append(f\"  - {v}\")\n",
    "        sb.append(\"\\n\")\n",
    "    return \"\\n\".join(sb)\n",
    "# print(format_labels(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "super hacky way to dynamically create pydantic schemas from the generated data from the `LabelerAgent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'ESG_Sentiment': {'description': 'Sentiment classification of ESG-related text', 'enum': ['positive', 'negative', 'neutral'], 'title': 'Esg Sentiment', 'type': 'string'}, 'CSR_Performance': {'description': 'Classification of CSR performance', 'enum': ['strong', 'weak', 'low', 'high'], 'title': 'Csr Performance', 'type': 'string'}, 'ESG_Rating': {'description': 'Classification of ESG rating', 'enum': ['low', 'medium', 'high'], 'title': 'Esg Rating', 'type': 'string'}, 'ESG_Topic': {'description': 'Classification of ESG topic', 'enum': ['sustainable', 'non-sustainable'], 'title': 'Esg Topic', 'type': 'string'}}, 'required': ['ESG_Sentiment', 'CSR_Performance', 'ESG_Rating', 'ESG_Topic'], 'title': 'DynamicLabelModel', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "annotations = {}\n",
    "field_definitions = {}\n",
    "\n",
    "for label in labels:\n",
    "    # workaround for python identifiers\n",
    "    field_name = label['label_name'].replace(\" \", \"_\")\n",
    "    # we don't know the type, so we use literals for the possible values (instead of str...)\n",
    "    field_type = Literal[tuple(label['possible_values'])]   \n",
    "    annotations[field_name] = field_type\n",
    "    field_definitions[field_name] = Field(..., description=label['description']) \n",
    "\n",
    "# Dynamically create the Pydantic model\n",
    "DynamicLabelModel = type(\n",
    "    \"DynamicLabelModel\", \n",
    "    (BaseModel,), \n",
    "    {\"__annotations__\": annotations, **field_definitions}\n",
    ")\n",
    "print(DynamicLabelModel.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataGenerationAgent(Agent):\n",
    "    def system(self):\n",
    "        pass\n",
    "\n",
    "    def prompt(\n",
    "        self,\n",
    "        labels: List[dict],\n",
    "        num_samples: int,\n",
    "        text_strategy: str,\n",
    "    ):\n",
    "        labels_str = format_labels(labels)\n",
    "        return f\"Generate {num_samples} unique sample {text_strategy} as if retrieved from realistic sources, related to the of {TOPIC}. Use the labeling definitions below: {labels_str}. Think creatively, and avoid similar language. Output in JSON.\"\n",
    "\n",
    "    def schema(self):\n",
    "        class DataSample(BaseModel):\n",
    "            text: str\n",
    "            # text: str = Field(\n",
    "            #     title=\"Text\",\n",
    "            #     description=\"The text of the data sample on the topic of {TOPIC}.\",\n",
    "            #     # min_length=200,\n",
    "            #     # max_length=500,\n",
    "            # )\n",
    "            labels: List[DynamicLabelModel]\n",
    "\n",
    "        class DataGenerationSchema(BaseModel):\n",
    "            samples: List[DataSample]\n",
    "\n",
    "        return DataGenerationSchema.model_json_schema()\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        labels: List[dict],\n",
    "        num_samples: int,\n",
    "        text_strategy: str,\n",
    "        output_key: str = \"samples\",\n",
    "    ):\n",
    "        output = generate(\n",
    "            system_prompt=self.system(),\n",
    "            prompt=self.prompt(\n",
    "                labels=labels, num_samples=num_samples, text_strategy=text_strategy\n",
    "            ),\n",
    "            schema=self.schema(),\n",
    "            model=model,\n",
    "            num_ctx=4000,\n",
    "            num_predict=3000,\n",
    "            temperature=1.0,  # we keep a high temp for more \"creative\" text generation\n",
    "        )\n",
    "        if output:\n",
    "            return output[output_key]\n",
    "\n",
    "\n",
    "data_generation_agent = DataGenerationAgent()\n",
    "\n",
    "text_strategy = \"sentences\"  # sentences | paragraphs | documents\n",
    "num_samples = 10\n",
    "batch_size = 10\n",
    "\n",
    "generated_data = []\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch = data_generation_agent(\n",
    "        labels=labels, num_samples=batch_size, text_strategy=text_strategy\n",
    "    )\n",
    "    generated_data.extend(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"The company's new sustainable energy project will create hundreds of jobs in the community, promoting a positive ESG sentiment.\",\n",
       "  'labels': [{'ESG_Sentiment': 'positive',\n",
       "    'CSR_Performance': 'high',\n",
       "    'ESG_Rating': 'high',\n",
       "    'ESG_Topic': 'sustainable'}]},\n",
       " {'text': \"The city council voted to pass a weak CSR policy, sparking concerns about the city's ESG rating.\",\n",
       "  'labels': [{'ESG_Sentiment': 'negative',\n",
       "    'CSR_Performance': 'weak',\n",
       "    'ESG_Rating': 'medium',\n",
       "    'ESG_Topic': 'non-sustainable'}]},\n",
       " {'text': \"The company's annual report highlights its strong commitment to sustainable practices, resulting in a high ESG rating.\",\n",
       "  'labels': [{'ESG_Sentiment': 'positive',\n",
       "    'CSR_Performance': 'high',\n",
       "    'ESG_Rating': 'high',\n",
       "    'ESG_Topic': 'sustainable'}]},\n",
       " {'text': 'A recent study found that the majority of consumers prioritize non-sustainable business practices, leading to a negative ESG sentiment.',\n",
       "  'labels': [{'ESG_Sentiment': 'negative',\n",
       "    'CSR_Performance': 'weak',\n",
       "    'ESG_Rating': 'low',\n",
       "    'ESG_Topic': 'non-sustainable'}]},\n",
       " {'text': \"The company's CSR efforts have not been effective in reducing its carbon footprint, resulting in a low ESG rating.\",\n",
       "  'labels': [{'ESG_Sentiment': 'negative',\n",
       "    'CSR_Performance': 'low',\n",
       "    'ESG_Rating': 'low',\n",
       "    'ESG_Topic': 'non-sustainable'}]},\n",
       " {'text': 'The new sustainable packaging design will reduce waste by 50%, resulting in a high ESG rating.',\n",
       "  'labels': [{'ESG_Sentiment': 'positive',\n",
       "    'CSR_Performance': 'high',\n",
       "    'ESG_Rating': 'high',\n",
       "    'ESG_Topic': 'sustainable'}]},\n",
       " {'text': 'A survey of customers found that they prioritize sustainable business practices, leading to a strong CSR performance.',\n",
       "  'labels': [{'ESG_Sentiment': 'positive',\n",
       "    'CSR_Performance': 'strong',\n",
       "    'ESG_Rating': 'medium',\n",
       "    'ESG_Topic': 'sustainable'}]},\n",
       " {'text': \"The company's ESG rating has been downgraded due to its increasing carbon footprint, resulting in a low ESG rating.\",\n",
       "  'labels': [{'ESG_Sentiment': 'negative',\n",
       "    'CSR_Performance': 'low',\n",
       "    'ESG_Rating': 'low',\n",
       "    'ESG_Topic': 'non-sustainable'}]},\n",
       " {'text': \"The city's new sustainability initiative aims to reduce energy consumption by 75%, resulting in a high ESG rating.\",\n",
       "  'labels': [{'ESG_Sentiment': 'positive',\n",
       "    'CSR_Performance': 'high',\n",
       "    'ESG_Rating': 'high',\n",
       "    'ESG_Topic': 'sustainable'}]},\n",
       " {'text': \"The company's CSR efforts have been effective in promoting a positive ESG sentiment, resulting in a strong ESG rating.\",\n",
       "  'labels': [{'ESG_Sentiment': 'positive',\n",
       "    'CSR_Performance': 'strong',\n",
       "    'ESG_Rating': 'high',\n",
       "    'ESG_Topic': 'sustainable'}]},\n",
       " {'text': \"The industry's high carbon footprint has led to a low ESG rating, resulting in a weak CSR performance.\",\n",
       "  'labels': [{'ESG_Sentiment': 'negative',\n",
       "    'CSR_Performance': 'weak',\n",
       "    'ESG_Rating': 'low',\n",
       "    'ESG_Topic': 'non-sustainable'}]}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ESG_Sentiment</th>\n",
       "      <th>CSR_Performance</th>\n",
       "      <th>ESG_Rating</th>\n",
       "      <th>ESG_Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The company's new sustainable energy project w...</td>\n",
       "      <td>positive</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The city council voted to pass a weak CSR poli...</td>\n",
       "      <td>negative</td>\n",
       "      <td>weak</td>\n",
       "      <td>medium</td>\n",
       "      <td>non-sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The company's annual report highlights its str...</td>\n",
       "      <td>positive</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A recent study found that the majority of cons...</td>\n",
       "      <td>negative</td>\n",
       "      <td>weak</td>\n",
       "      <td>low</td>\n",
       "      <td>non-sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The company's CSR efforts have not been effect...</td>\n",
       "      <td>negative</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>non-sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The new sustainable packaging design will redu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A survey of customers found that they prioriti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>strong</td>\n",
       "      <td>medium</td>\n",
       "      <td>sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The company's ESG rating has been downgraded d...</td>\n",
       "      <td>negative</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>non-sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The city's new sustainability initiative aims ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The company's CSR efforts have been effective ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>strong</td>\n",
       "      <td>high</td>\n",
       "      <td>sustainable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The industry's high carbon footprint has led t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>weak</td>\n",
       "      <td>low</td>\n",
       "      <td>non-sustainable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text ESG_Sentiment  \\\n",
       "0   The company's new sustainable energy project w...      positive   \n",
       "1   The city council voted to pass a weak CSR poli...      negative   \n",
       "2   The company's annual report highlights its str...      positive   \n",
       "3   A recent study found that the majority of cons...      negative   \n",
       "4   The company's CSR efforts have not been effect...      negative   \n",
       "5   The new sustainable packaging design will redu...      positive   \n",
       "6   A survey of customers found that they prioriti...      positive   \n",
       "7   The company's ESG rating has been downgraded d...      negative   \n",
       "8   The city's new sustainability initiative aims ...      positive   \n",
       "9   The company's CSR efforts have been effective ...      positive   \n",
       "10  The industry's high carbon footprint has led t...      negative   \n",
       "\n",
       "   CSR_Performance ESG_Rating        ESG_Topic  \n",
       "0             high       high      sustainable  \n",
       "1             weak     medium  non-sustainable  \n",
       "2             high       high      sustainable  \n",
       "3             weak        low  non-sustainable  \n",
       "4              low        low  non-sustainable  \n",
       "5             high       high      sustainable  \n",
       "6           strong     medium      sustainable  \n",
       "7              low        low  non-sustainable  \n",
       "8             high       high      sustainable  \n",
       "9           strong       high      sustainable  \n",
       "10            weak        low  non-sustainable  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(generated_data[0].keys()) + list(generated_data[0][\"labels\"][0].keys())\n",
    "columns.remove(\"labels\")\n",
    "data = []\n",
    "for sample in generated_data:\n",
    "    # print(sample)\n",
    "    for label in sample[\"labels\"]:\n",
    "        data.append({**sample, **label})\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}