{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "pseudo code for what we want (taken from <https://huggingface.co/docs/smolagents/v1.3.0/en/conceptual_guides/intro_agents>)\n",
    "\n",
    "```\n",
    "memory = [user_defined_task]\n",
    "while llm_should_continue(memory): # this loop is the multi-step part\n",
    "    action = llm_get_next_action(memory) # this is the tool-calling part\n",
    "    observations = execute_action(action)\n",
    "    memory += [action, observations]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experimental!!!\n",
    "stop the ollama service and start it as follows (assume you have memory for 3 models, we're using lightweight ones!)\n",
    "```bash\n",
    "OLLAMA_MAX_LOADED_MODELS=3 OLLAMA_NUM_PARALLEL=3 ollama serve\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-3.2-1b\n",
      "llama-3.2-3b\n",
      "llama-3.1-8b\n",
      "deepseek-qwen-32b\n",
      "gemma-2-9b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hf.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF:IQ4_NL'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a model\n",
    "from util import load_model, show_models\n",
    "print(show_models())\n",
    "model = load_model(model_id=\"llama-3.1-8b\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selenium web driver\n",
    "we use this to control the agents' online presence :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSeleniumManagerException\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/common/service.py:97\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mSeleniumManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WebDriverException \u001b[38;5;28;01mas\u001b[39;00m new_err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/common/selenium_manager.py:74\u001b[0m, in \u001b[0;36mSeleniumManager.driver_location\u001b[0;34m(self, browser)\u001b[0m\n\u001b[1;32m     73\u001b[0m binary, flag, browser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_binary()), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--browser\u001b[39m\u001b[38;5;124m\"\u001b[39m, browser\n\u001b[0;32m---> 74\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m executable \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/common/selenium_manager.py:93\u001b[0m, in \u001b[0;36mSeleniumManager.run\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m completed_proc\u001b[38;5;241m.\u001b[39mreturncode:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SeleniumManagerException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelenium manager failed for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommand\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# selenium manager exited 0 successfully, parse the executable path from stdout.\u001b[39;00m\n",
      "\u001b[0;31mSeleniumManagerException\u001b[0m: Message: Selenium manager failed for: /opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/common/macos/selenium-manager --browser chrome. \n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/chrome/webdriver.py:81\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service:\n\u001b[1;32m     79\u001b[0m     service \u001b[38;5;241m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesired_capabilities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/chromium/webdriver.py:103\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    107\u001b[0m         command_executor\u001b[38;5;241m=\u001b[39mChromiumRemoteConnection(\n\u001b[1;32m    108\u001b[0m             remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    115\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/common/service.py:100\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m WebDriverException \u001b[38;5;28;01mas\u001b[39;00m new_err:\n\u001b[1;32m     99\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to obtain driver using Selenium Manager: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m new_err\u001b[38;5;241m.\u001b[39mmsg)\n\u001b[0;32m--> 100\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_process(path)\n\u001b[1;32m    104\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/common/service.py:90\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03mStarts the Service.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m   or when it can't connect to the service\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_process\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WebDriverException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecutable needs to be in PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m err\u001b[38;5;241m.\u001b[39mmsg:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/common/service.py:213\u001b[0m, in \u001b[0;36mService._start_process\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m    214\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m executable needs to be in PATH. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_error_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m         )\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mEACCES:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m executable may have wrong permissions. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_error_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         )\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from pydantic import BaseModel, Field, Json\n",
    "from typing import List, Any\n",
    "\n",
    "\n",
    "class Agent(ABC):\n",
    "    @abstractmethod\n",
    "    def system(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def prompt(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def schema(self) -> dict[str, Any]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate speech detection datasets OR hateful speech datasets OR toxic language datasets OR abusive language datasets OR offensive language datasets OR hate speech classification datasets OR hate speech detection models OR hate speech datasets for machine learning OR datasets for hate speech detection OR resources for hate speech detection research\n"
     ]
    }
   ],
   "source": [
    "from generate import generate\n",
    "\n",
    "# tools = [\n",
    "#     \"search_engine\",\n",
    "#     \"dataset_generator\"\n",
    "# ]\n",
    "# tools_str = \", \".join(f\"{i+1}. {tool}\" for i, tool in enumerate(tools))\n",
    "\n",
    "# main_system = f\"You are an intelligent assistant that helps the user in the necessary steps required to generate a dataset. Based on the users input, you should create tasks as described by the  {len(tools)} tools you have available: {tools_str}.\"\n",
    "# print(main_system)\n",
    "\n",
    "\n",
    "class SearchAgent(Agent):\n",
    "    def system(self):\n",
    "        return \"You are tasked with reformulating a topic into a search string. You will aid the user to find more information about the datasets and resources available for said topic. Answer in JSON.\"\n",
    "    \n",
    "    def prompt(self, topic: str):\n",
    "        return f\"Generate a Google keyword search that will help the user find datasets on the topic of {topic}. Do not constrain the search to specific sites. Use your knowledge of the topic to generate a comprehensive search string.\"\n",
    "    \n",
    "    def schema(self):\n",
    "        class SearchSchema(BaseModel):\n",
    "            search: str\n",
    "        return SearchSchema.model_json_schema()\n",
    "    \n",
    "    def __call__(self, topic: str):\n",
    "        return generate(\n",
    "            system_prompt=self.system(),\n",
    "            prompt=self.prompt(topic),\n",
    "            schema=self.schema(),\n",
    "            model=model,\n",
    "            num_ctx=1000,\n",
    "            temperature=0.5\n",
    "        )[\"search\"]\n",
    "\n",
    "\n",
    "TOPIC = \"hateful speech detection\"\n",
    "main_prompt = f\"I want to create a dataset on the topic of {TOPIC}.\"\n",
    "search_agent = SearchAgent()\n",
    "\n",
    "search_string = search_agent(topic=TOPIC)\n",
    "print(search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "# ddgs = DDGS(proxy=\"tb\", timeout=20) \n",
    "# this requires the TOR browser to be installed and running for a proxy\n",
    "# should be used if you plan on querying a lot.\n",
    "ddgs = DDGS(timeout=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://hatespeechdata.com/']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_urls(search_string: str, max_results: int = 1):\n",
    "    res = ddgs.text(search_string, max_results=max_results, region=\"us-en\", safesearch=\"on\")\n",
    "    hrefs = [r[\"href\"] for r in res]\n",
    "    return hrefs\n",
    "\n",
    "urls = get_urls(search_string)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown\n",
    "\n",
    "md = MarkItDown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "LANGUAGE = \"English\"\n",
    "search_for_dataset_info_query = \"From the provided markdown text:\\n{MARKDOWN}\\nFind direct links to datasets, descriptions of datasets, and other information that explains something about the data. The dataset should be in {LANGUAGE}.\"\n",
    "\n",
    "def visit_site(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    html = driver.page_source\n",
    "    return html\n",
    "\n",
    "html = visit_site(urls[0])\n",
    "\n",
    "TMP = \"tmp.html\"\n",
    "with open(TMP, \"w\") as f:\n",
    "    f.write(html)\n",
    "result = md.convert(TMP)\n",
    "\n",
    "# to deal with large contexts, split by headlines\n",
    "hashed_results = result.text_content.split(\"\\n#\")\n",
    "hashed_results = [h.strip() for h in hashed_results if len(h.strip().split(\"\\n\")) > 1]\n",
    "\n",
    "TMP_FOLDER = \"tmp-markdown\"\n",
    "shutil.rmtree(TMP_FOLDER, ignore_errors=True)\n",
    "os.makedirs(TMP_FOLDER, exist_ok=True)\n",
    "\n",
    "for i, hashed_result in enumerate(hashed_results):\n",
    "    with open(f\"tmp-markdown/{i}.md\", \"w\") as f:\n",
    "        f.write(hashed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp-markdown/0.md\n",
      "[{'name': 'Hate Speech Dataset Catalogue', 'language': 'English', 'url': 'https://hatespeechdata.github.io/', 'labels': [], 'relevant': 'yes'}, {'name': 'IMDB Dataset', 'language': 'English', 'url': 'https://www.imdb.com/', 'labels': [], 'relevant': 'yes'}, {'name': 'Twitter Hateful Sentiment Dataset', 'language': 'English', 'url': 'https://www.kaggle.com/datasnaek/twitter-sentiment', 'labels': [], 'relevant': 'yes'}, {'name': 'OffensEval Dataset', 'language': 'English', 'url': 'https://competitions.codalab.org/competitions/22120', 'labels': [], 'relevant': 'yes'}, {'name': 'SemEval-2019 Task 6 Dataset', 'language': 'English', 'url': 'https://competitions.codalab.org/competitions/21200', 'labels': [], 'relevant': 'yes'}, {'name': 'Google Hate Speech Dataset', 'language': 'English', 'url': 'https://www.kaggle.com/competitions/google-hate-speech', 'labels': [], 'relevant': 'yes'}, {'name': 'Toxic Comment Classification Dataset', 'language': 'English', 'url': 'https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge', 'labels': [], 'relevant': 'yes'}, {'name': 'Reddit Hateful Speech Dataset', 'language': 'English', 'url': 'https://www.kaggle.com/datasnaek/reddit-hateful-speech', 'labels': [], 'relevant': 'yes'}, {'name': 'DebateHate Dataset', 'language': 'English', 'url': 'https://www.kaggle.com/competitions/debatehate', 'labels': [], 'relevant': 'yes'}, {'name': 'Hate Speech Dataset by Zampolli et al.', 'language': 'English', 'url': 'https://www.kaggle.com/competitions/hate-speech-dataset-by-zampolli-et-al', 'labels': [], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/1.md\n",
      "[{'name': 'English', 'language': 'English', 'url': 'https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data', 'labels': [{'name': 'toxic', 'num_labels': 1, 'description': 'Toxicity'}, {'name': 'severe_toxicity', 'num_labels': 1, 'description': 'Severe toxicity'}, {'name': 'obscene', 'num_labels': 1, 'description': 'Obscenity'}, {'name': 'insult', 'num_labels': 1, 'description': 'Insult'}, {'name': 'identity_hate', 'num_labels': 1, 'description': 'Identity hate'}], 'relevant': 'yes'}, {'name': 'English', 'language': 'English', 'url': 'https://www.kaggle.com/c/hate-speech-detection/data', 'labels': [{'name': 'hate_speech', 'num_labels': 1, 'description': 'Hate speech'}, {'name': 'offensive', 'num_labels': 1, 'description': 'Offensiveness'}, {'name': 'neither', 'num_labels': 1, 'description': 'Neither hate speech nor offensiveness'}], 'relevant': 'yes'}, {'name': 'English', 'language': 'English', 'url': 'https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data', 'labels': [{'name': 'toxic', 'num_labels': 1, 'description': 'Toxicity'}, {'name': 'severe_toxicity', 'num_labels': 1, 'description': 'Severe toxicity'}, {'name': 'obscene', 'num_labels': 1, 'description': 'Obscenity'}, {'name': 'insult', 'num_labels': 1, 'description': 'Insult'}, {'name': 'identity_hate', 'num_labels': 1, 'description': 'Identity hate'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/2.md\n",
      "[{'name': 'Detecting Abusive Albanian', 'language': 'Albanian', 'url': 'https://doi.org/10.6084/m9.figshare.19333298.v1', 'labels': [{'name': 'offensive/not', 'num_labels': 2, 'description': 'Hierarchical (offensive/not; untargeted/targeted; person/group/other)'}, {'name': 'untargeted/targeted', 'num_labels': 2, 'description': 'Hierarchical (offensive/not; untargeted/targeted; person/group/other)'}, {'name': 'person/group/other', 'num_labels': 3, 'description': 'Hierarchical (offensive/not; untargeted/targeted; person/group/other)'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/3.md\n",
      "[{'name': 'Let-Mi: An Arabic Levantine Twitter Dataset for Misogynistic Language', 'language': 'Arabic', 'url': 'https://drive.google.com/file/d/1mM2vnjsy7QfUmdVUpKqHRJjZyQobhTrW/view', 'labels': [{'name': 'misogyny', 'num_labels': 2, 'description': 'none'}, {'name': 'multi-class', 'num_labels': 9, 'description': 'none, discredit, derailing, dominance, stereotyping & objectiﬁcation, threat of violence, sexual harassment, damning'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/4.md\n",
      "[{'name': 'Are They our Brothers? Analysis and Detection of Religious Hate Speech in the Arabic Twittersphere', 'language': 'Arabic', 'url': 'https://github.com/nuhaalbadi/Arabic_hatespeech', 'labels': [{'name': 'Hate', 'num_labels': 1, 'description': 'Not'}, {'name': 'Religious subcategories', 'num_labels': 1, 'description': 'Details of task'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/5.md\n",
      "[{'name': 'Multilingual and Multi-Aspect Hate Speech Analysis (Arabic)', 'language': 'Arabic', 'url': 'https://github.com/HKUST-KnowComp/MLMA_hate_speech', 'labels': [{'name': 'Hostility', 'num_labels': 1, 'description': 'Detailed taxonomy with cross-cutting attributes'}, {'name': 'Directness', 'num_labels': 1, 'description': 'Detailed taxonomy with cross-cutting attributes'}, {'name': 'Target Attribute', 'num_labels': 1, 'description': 'Detailed taxonomy with cross-cutting attributes'}, {'name': 'Target Group', 'num_labels': 1, 'description': 'Detailed taxonomy with cross-cutting attributes'}, {'name': 'How annotators felt on seeing the tweet', 'num_labels': 1, 'description': 'Detailed taxonomy with cross-cutting attributes'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/6.md\n",
      "[{'name': 'L-HSAB', 'language': 'Arabic', 'url': 'https://github.com/Hala-Mulki/L-HSAB-First-Arabic-Levantine-HateSpeech-Dataset', 'labels': [{'name': 'Hate', 'num_labels': 1, 'description': 'Group-directed + Person-directed'}, {'name': 'Abusive', 'num_labels': 1, 'description': 'Group-directed + Person-directed'}, {'name': 'Normal', 'num_labels': 1, 'description': 'Group-directed + Person-directed'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/7.md\n",
      "[{'name': 'Abusive Language Detection on Arabic Social Media (Twitter)', 'language': 'Arabic', 'url': 'http://alt.qcri.org/~hmubarak/offensive/TweetClassification-Summary.xlsx', 'labels': [{'name': 'Obscene', 'num_labels': 1, 'description': 'Obscene'}, {'name': 'Offensive but not obscene', 'num_labels': 1, 'description': 'Offensive but not obscene'}, {'name': 'Clean', 'num_labels': 1, 'description': 'Clean'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/8.md\n",
      "[{'name': 'Abusive Language Detection on Arabic Social Media (Al Jazeera)', 'language': 'Arabic', 'url': 'http://alt.qcri.org/~hmubarak/offensive/AJCommentsClassification-CF.xlsx', 'labels': [{'name': 'Obscene', 'num_labels': 1, 'description': 'Obscene'}, {'name': 'Offensive but not obscene', 'num_labels': 1, 'description': 'Offensive but not obscene'}, {'name': 'Clean', 'num_labels': 1, 'description': 'Clean'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/9.md\n",
      "[{'name': 'Dataset Construction for the Detection of Anti-Social Behaviour in Online Communication in Arabic', 'language': 'Arabic', 'url': 'https://onedrive.live.com/?authkey=!ACDXj_ZNcZPqzy0&id=6EF6951FBF8217F9!105&cid=6EF6951FBF8217F9', 'labels': [{'name': 'Offensive', 'num_labels': 1, 'description': 'Not'}, {'name': 'Not', 'num_labels': 1, 'description': 'Offensive'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/10.md\n",
      "[{'name': 'Hate Speech Detection in the Bengali language: A Dataset and its Baseline Evaluation', 'language': 'Bengali', 'url': 'https://www.kaggle.com/naurosromim/bengali-hate-speech-dataset', 'labels': [{'name': 'hateful', 'num_labels': 1, 'description': 'not'}, {'name': 'sports', 'num_labels': 1, 'description': 'entertainment'}, {'name': 'crime', 'num_labels': 1, 'description': 'religion'}, {'name': 'politics', 'num_labels': 1, 'description': 'celebrity'}, {'name': 'meme', 'num_labels': 1, 'description': 'not'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/11.md\n",
      "[{'name': 'SWSR', 'language': 'Chinese', 'url': 'https://doi.org/10.5281/zenodo.4773875', 'labels': [{'name': 'Sexist', 'num_labels': 1, 'description': 'Binary classification of sexist or non-sexist comments'}, {'name': 'Categories of sexism', 'num_labels': 4, 'description': 'Stereotype based on Appearance, Stereotype based on Cultural Background, MicroAggression, and Sexual Offense'}, {'name': 'Target of sexism', 'num_labels': 2, 'description': 'Individual or Generic'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/12.md\n",
      "[{'name': 'CoRAL', 'language': 'Croatian', 'url': 'https://github.com/shekharRavi/CoRAL-dataset-Findings-of-the-ACL-AACL-IJCNLP-2022', 'labels': [{'name': 'CDC', 'num_labels': 1, 'description': 'Context dependency categories'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/13.md\n",
      "[{'name': 'Slovene and Croatian Moderated News Comments', 'language': 'Croatian', 'url': 'http://hdl.handle.net/11356/1202', 'labels': [{'name': 'Deleted', 'num_labels': 1, 'description': 'Flagged content'}, {'name': 'Not', 'num_labels': 1, 'description': 'Not flagged content'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/14.md\n",
      "[{'name': 'Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian', 'language': 'Croatian', 'url': 'https://www.clarin.si/repository/xmlui/handle/11356/1399', 'labels': [{'name': 'Abusive', 'num_labels': 0, 'description': 'Flagged content performed by the real newspaper moderators'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/15.md\n",
      "[{'name': 'Danish Hate Speech Abusive Language data', 'language': 'Danish', 'url': 'https://figshare.com/articles/Danish_Hate_Speech_Abusive_Language_data/12220805', 'labels': [{'name': 'Offensive', 'num_labels': 1, 'description': 'Offensive language'}, {'name': 'Not', 'num_labels': 1, 'description': 'Not offensive language'}, {'name': 'Target', 'num_labels': 1, 'description': 'Target of hate speech'}, {'name': 'Individual', 'num_labels': 1, 'description': 'Individual target'}, {'name': 'Group', 'num_labels': 1, 'description': 'Group target'}, {'name': 'Other', 'num_labels': 1, 'description': 'Other target'}], 'relevant': 'no'}, {'name': 'DDSC/dkhate', 'language': 'Danish', 'url': 'https://huggingface.co/datasets/DDSC/dkhate', 'labels': [{'name': 'Offensive', 'num_labels': 1, 'description': 'Offensive language'}, {'name': 'Not', 'num_labels': 1, 'description': 'Not offensive language'}, {'name': 'Target', 'num_labels': 1, 'description': 'Target of hate speech'}, {'name': 'Individual', 'num_labels': 1, 'description': 'Individual target'}, {'name': 'Group', 'num_labels': 1, 'description': 'Group target'}, {'name': 'Other', 'num_labels': 1, 'description': 'Other target'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/16.md\n",
      "[{'name': 'BAJER: Misogyny in Danish', 'language': 'Danish', 'url': 'https://docs.google.com/forms/d/e/1FAIpQLSfUKb7ZTKd01syaNkAW5GDfCSkaVsJlom06g_mJdWUkUikVHA/viewform', 'labels': [{'name': 'Misogyny', 'num_labels': 7, 'description': 'Hierarchy of abusive content labels including subcategories of misogyny'}, {'name': 'Abusive', 'num_labels': 27, 'description': 'Subcategories of abusive content'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/17.md\n",
      "[{'name': 'Dutch Abusive Language Corpus v1.0 (DALC v1.0)', 'language': 'Dutch', 'url': 'https://github.com/tommasoc80/DALC', 'labels': [{'name': 'explicitly abusive', 'num_labels': 1516, 'description': 'implicitly abusive'}, {'name': 'implicitly abusive', 'num_labels': 809, 'description': 'Abusive language detection in social media'}, {'name': 'relevant', 'num_labels': 0, 'description': 'Hateful speech detection'}], 'relevant': 'no'}]\n",
      "___\n",
      "tmp-markdown/18.md\n",
      "[{'name': 'counterhate_reply', 'language': 'English', 'url': 'https://github.com/albanyan/counterhate_reply', 'labels': [{'name': 'Agree', 'num_labels': 1, 'description': 'Whether the reply to a counterhate tweet agrees with the counterhate tweet'}, {'name': 'Support_Hateful-tweet', 'num_labels': 1, 'description': 'Whether the reply to a counterhate tweet supports the hateful tweet'}, {'name': 'Attack_Author', 'num_labels': 1, 'description': 'Whether the reply to a counterhate tweet attacks the author of the counterhate tweet'}, {'name': 'Additional_Counterhate', 'num_labels': 1, 'description': 'Whether the reply to a counterhate tweet adds additional counterhate'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/19.md\n",
      "[{'name': 'Hateful Tweets and Replies', 'language': 'English', 'url': 'https://github.com/albanyan/hateful-tweets-replies', 'labels': [{'name': 'Counterhate', 'num_labels': 1, 'description': 'Indicates whether the reply to a hateful tweet is counter hate speech'}, {'name': 'Not', 'num_labels': 1, 'description': 'Indicates whether the reply to a hateful tweet is not counter hate speech'}, {'name': 'Counterhate_with_Justification', 'num_labels': 1, 'description': 'Indicates whether the reply to a hateful tweet provides a justification'}, {'name': 'Not', 'num_labels': 1, 'description': 'Indicates whether the reply to a hateful tweet does not provide a justification'}, {'name': 'Attack_Author', 'num_labels': 1, 'description': 'Indicates whether the reply to a hateful tweet attacks the author of the tweet'}, {'name': 'Not', 'num_labels': 1, 'description': 'Indicates whether the reply to a hateful tweet does not attack the author of the tweet'}, {'name': 'Additional_Hate', 'num_labels': 1, 'description': 'Indicates whether the reply to a hateful tweet adds additional hate'}, {'name': 'Not', 'num_labels': 1, 'description': 'Indicates whether the reply to a hateful tweet does not add additional hate'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/20.md\n",
      "[{'name': 'Large-Scale Hate Speech Detection with Cross-Domain Transfer', 'language': 'English', 'url': 'https://github.com/avaapm/hatespeech', 'labels': [{'name': 'Hate speech', 'num_labels': 27593, 'description': 'Offensive language'}, {'name': 'None', 'num_labels': 41660, 'description': 'None'}], 'relevant': 'yes'}, {'name': 'Online-Abusive-Attacks-OAA-Dataset', 'language': 'English', 'url': 'https://github.com/RaneemAlharthi/Online-Abusive-Attacks-OAA-Dataset', 'labels': [{'name': 'Abusive', 'num_labels': 10690000, 'description': 'Not abusive'}, {'name': 'Toxicity', 'num_labels': 10690000, 'description': 'Severe toxicity'}, {'name': 'Identity attack', 'num_labels': 10690000, 'description': 'Insult'}, {'name': 'Profanity', 'num_labels': 10690000, 'description': 'Threat'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/21.md\n",
      "[{'name': 'ConvAbuse', 'language': 'English', 'url': 'https://github.com/amandacurry/convabuse', 'labels': [{'name': 'Abuse binary', 'num_labels': 2, 'description': 'Hierarchical: Abuse severity 1,0,-1,-2,-3'}, {'name': 'Directedness', 'num_labels': 2, 'description': 'explicit, implicit'}, {'name': 'Target', 'num_labels': 4, 'description': 'group, individual–system, individual–3rd party'}, {'name': 'Type', 'num_labels': 8, 'description': 'general, sexist, sexual harassment, homophobic, racist, transphobic, ableist, intellectual'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/22.md\n",
      "[{'name': 'Measuring Hate Speech', 'language': 'English', 'url': 'https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech', 'labels': [{'name': 'sentiment', 'num_labels': 10, 'description': 'ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech)'}, {'name': 'hate_speech_score', 'num_labels': 1, 'description': 'continuous hate speech severity score'}, {'name': 'target_identity_groups', 'num_labels': 8, 'description': 'race/ethnicity, religion, national origin/citizenship, gender, sexual orientation, age, disability, political ideology'}, {'name': 'identity_subgroups', 'num_labels': 42, 'description': '42 identity subgroups'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/23.md\n",
      "[{'name': 'Learning From the Worst (Dynamically generated hate speech dataset)', 'language': 'English', 'url': 'https://github.com/bvidgen/Dynamically-Generated-Hate-Speech-Dataset', 'labels': [{'name': 'Hate speech detection', 'num_labels': 2, 'description': 'Multi-category hate speech detection with fine-grained labels for the type and target of hate.'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/24.md\n",
      "[{'name': 'The ‘Call me sexist, but’ sexism dataset', 'language': 'English', 'url': 'https://doi.org/10.7802/2251', 'labels': [{'name': 'sexism', 'num_labels': 6325, 'description': 'Sexism detection based on content and phrasing'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/25.md\n",
      "[{'name': 'Hate Towards the Political Opponent: A Twitter Corpus Study of the 2020 US Elections on the Basis of Offensive Speech and Stance Detection', 'language': 'English', 'url': 'https://www.ims.uni-stuttgart.de/data/stance_hof_us2020', 'labels': [{'name': 'Hate', 'num_labels': 1, 'description': 'Hate speech'}, {'name': 'Offensive', 'num_labels': 1, 'description': 'Offensive speech'}, {'name': 'Neither', 'num_labels': 1, 'description': 'Neither hate nor offensive speech'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/26.md\n",
      "[{'name': 'AbuseEval v1.0', 'language': 'English', 'url': 'https://github.com/tommasoc80/AbuseEval', 'labels': [{'name': 'EXPLICIT', 'num_labels': 1, 'description': 'Explicit offensive message'}, {'name': 'IMPLICIT', 'num_labels': 1, 'description': 'Implicit offensive message'}, {'name': 'NOT', 'num_labels': 1, 'description': 'Not an offensive message'}, {'name': 'EXPLICIT', 'num_labels': 1, 'description': 'Explicit abusive message'}, {'name': 'IMPLICIT', 'num_labels': 1, 'description': 'Implicit abusive message'}, {'name': 'NOTABU', 'num_labels': 1, 'description': 'Not an abusive message'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/27.md\n",
      "[{'name': 'SWAD-Repository', 'language': 'English', 'url': 'https://github.com/dadangewp/SWAD-Repository', 'labels': [{'name': 'Abusive swear word', 'num_labels': 1, 'description': 'Non-abusive swear word'}, {'name': 'Non-abusive swear word', 'num_labels': 1, 'description': 'Abusive swearing'}, {'name': 'Abusive swearing', 'num_labels': 1, 'description': 'Binary (abusive swear word, non-abusive swear word)'}, {'name': 'Binary (abusive swear word, non-abusive swear word)', 'num_labels': 1, 'description': 'Task description'}, {'name': 'Task description', 'num_labels': 1, 'description': 'Size of dataset'}, {'name': 'Size of dataset', 'num_labels': 1, 'description': '1,511 swear words (1675 tweets)'}, {'name': '1,511 swear words (1675 tweets)', 'num_labels': 1, 'description': 'Percentage abusive'}, {'name': 'Percentage abusive', 'num_labels': 1, 'description': '0.41% (word level), 0.51% (post level)'}, {'name': '0.41% (word level), 0.51% (post level)', 'num_labels': 1, 'description': 'Platform'}, {'name': 'Platform', 'num_labels': 1, 'description': 'Twitter'}, {'name': 'Twitter', 'num_labels': 1, 'description': 'Medium'}, {'name': 'Medium', 'num_labels': 1, 'description': 'Text'}, {'name': 'Text', 'num_labels': 1, 'description': 'Reference'}, {'name': 'Reference', 'num_labels': 1, 'description': 'Pamungkas, E. W., Basile, V., & Patti, V. (2020). Do you really want to hurt me? predicting abusive swearing in social media. In The 12th Language Resources and Evaluation Conference (pp. 6237-6246). European Language Resources Association.'}, {'name': 'Pamungkas, E. W., Basile, V., & Patti, V. (2020). Do you really want to hurt me? predicting abusive swearing in social media. In The 12th Language Resources and Evaluation Conference (pp. 6237-6246). European Language Resources Association.', 'num_labels': 1, 'description': 'Link to publication'}, {'name': 'Link to publication', 'num_labels': 1, 'description': 'https://www.aclweb.org/anthology/2020.lrec-1.765.pdf'}, {'name': 'https://www.aclweb.org/anthology/2020.lrec-1.765.pdf', 'num_labels': 1, 'description': 'Link to data'}, {'name': 'Link to data', 'num_labels': 1, 'description': 'https://github.com/dadangewp/SWAD-Repository'}, {'name': 'https://github.com/dadangewp/SWAD-Repository', 'num_labels': 1, 'description': 'relevant'}, {'name': 'relevant', 'num_labels': 1, 'description': 'true'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/28.md\n",
      "[{'name': 'Multimodal Meme Dataset (MultiOFF)', 'language': 'English', 'url': 'https://github.com/bharathichezhiyan/Multimodal-Meme-Classification-Identifying-Offensive-Content-in-Image-and-Text', 'labels': [{'name': 'offensive', 'num_labels': 1, 'description': 'Hate per se (related to 2016 U.S. presidential election)'}, {'name': 'non-offensive', 'num_labels': 1, 'description': 'Non-hateful content'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/29.md\n",
      "[{'name': 'HatemojiCheck', 'language': 'English', 'url': 'https://github.com/HannahKirk/Hatemoji', 'labels': [{'name': 'Hate', 'num_labels': 1, 'description': 'Hate speech detection for text statements including emoji'}, {'name': 'Not Hate', 'num_labels': 1, 'description': 'Non-hate speech detection for text statements including emoji'}], 'relevant': 'yes'}, {'name': 'HatemojiBuild', 'language': 'English', 'url': 'https://github.com/HannahKirk/Hatemoji', 'labels': [{'name': 'Hate', 'num_labels': 1, 'description': 'Hate speech detection for text statements including emoji'}, {'name': 'Not Hate', 'num_labels': 1, 'description': 'Non-hate speech detection for text statements including emoji'}, {'name': 'Type', 'num_labels': 1, 'description': 'Type of hate speech'}, {'name': 'Target', 'num_labels': 1, 'description': 'Target of hate speech'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/30.md\n",
      "[{'name': 'HateCheck', 'language': 'English', 'url': 'https://github.com/paul-rottger/hatecheck-data', 'labels': [{'name': 'Hate', 'num_labels': 1, 'description': 'Hate speech'}, {'name': 'Not Hate', 'num_labels': 1, 'description': 'Not hate speech'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/31.md\n",
      "[{'name': 'Semeval-2021 Task 5: Toxic Spans Detection', 'language': 'English', 'url': 'https://github.com/ipavlopoulos/toxic_spans', 'labels': [{'name': 'toxic', 'num_labels': 1, 'description': 'toxic spans'}, {'name': 'non-toxic', 'num_labels': 1, 'description': 'non-toxic spans'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/32.md\n",
      "[{'name': 'ToxiSpanSE', 'language': 'English', 'url': 'https://github.com/WSU-SEAL/ToxiSpanSE', 'labels': [{'name': 'Toxic', 'num_labels': 1, 'description': 'Toxic spans in code review comments'}, {'name': 'Non-toxic', 'num_labels': 1, 'description': 'Non-toxic spans in code review comments'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/33.md\n",
      "[{'name': 'CONAN', 'language': 'English', 'url': 'https://github.com/marcoguerini/CONAN', 'labels': [{'name': 'hateful', 'num_labels': 1, 'description': 'binary label indicating whether a post is hateful or not'}, {'name': 'race', 'num_labels': 1, 'description': 'label indicating whether a post targets race'}, {'name': 'religion', 'num_labels': 1, 'description': 'label indicating whether a post targets religion'}, {'name': 'country of origin', 'num_labels': 1, 'description': 'label indicating whether a post targets country of origin'}, {'name': 'sexual orientation', 'num_labels': 1, 'description': 'label indicating whether a post targets sexual orientation'}, {'name': 'disability', 'num_labels': 1, 'description': 'label indicating whether a post targets disability'}, {'name': 'gender', 'num_labels': 1, 'description': 'label indicating whether a post targets gender'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/34.md\n",
      "[{'name': 'HateXplain', 'language': 'English', 'url': 'https://github.com/punyajoy/HateXplain', 'labels': [{'name': 'Level of hate', 'num_labels': 3, 'description': 'hate, offensive or normal'}, {'name': 'Target groups', 'num_labels': 5, 'description': 'race, religion, gender, sexual orientation, miscellaneous'}, {'name': 'Rationales', 'num_labels': 1, 'description': 'rationales'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/35.md\n",
      "[{'name': 'ALONE', 'language': 'English', 'url': 'https://arxiv.org/pdf/2008.06465.pdf', 'labels': [{'name': 'Toxic', 'num_labels': 1, 'description': 'Binary (Toxic, Non-Toxic)'}, {'name': 'Non-Toxic', 'num_labels': 1, 'description': 'Binary (Toxic, Non-Toxic)'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/36.md\n",
      "[{'name': 'Slur Corpus', 'language': 'English', 'url': 'https://github.com/networkdynamics/slur-corpus', 'labels': [{'name': 'Derogatory', 'num_labels': 0, 'description': 'Derogatory language'}, {'name': 'Appropriate', 'num_labels': 0, 'description': 'Appropriate language'}, {'name': 'Non-Derogatory/Non-Appropriate', 'num_labels': 0, 'description': 'Non-derogatory and non-appropriate language'}, {'name': 'Homonyms', 'num_labels': 0, 'description': 'Words with multiple meanings'}, {'name': 'Noise', 'num_labels': 0, 'description': 'Irrelevant or unlabelled data'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/37.md\n",
      "[{'name': 'Multimodal Meme Dataset (MultiOFF)', 'language': 'English', 'url': 'https://www.aclweb.org/anthology/2020.trac-1.6.pdf', 'labels': [{'name': 'offensive', 'num_labels': 1, 'description': 'Hate per se (related to 2016 U.S. presidential election)'}, {'name': 'non-offensive', 'num_labels': 1, 'description': 'Non-hateful content'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/38.md\n",
      "[{'name': 'Predicting the Type and Target of Offensive Posts in Social Media', 'language': 'English', 'url': 'https://scholar.harvard.edu/malmasi/olid', 'labels': [{'name': 'offensive / not', 'num_labels': 2, 'description': 'Branching structure of tasks. A: offensive / not, B: targeted insult / untargeted, C: individual, group, other.'}, {'name': 'Hate per se', 'num_labels': 1, 'description': 'Details of task: Hate per se'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/39.md\n",
      "[{'name': 'Civil Comments', 'language': 'English', 'url': 'https://www.tensorflow.org/datasets/catalog/civil_comments', 'labels': [{'name': 'Toxicity', 'num_labels': 6, 'description': 'severe, obscene, threat, insult, identity attack, sexual explicit'}, {'name': 'Identity attributes', 'num_labels': 3, 'description': 'gender, religion, race'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/40.md\n",
      "[{'name': 'CAD: the Contextual Abuse Dataset', 'language': 'English', 'url': 'https://zenodo.org/record/4881008#.Ye6OwhP7R6o', 'labels': [{'name': 'Abusive + Identity-directed', 'num_labels': 4, 'description': 'derogation/animosity/threatening/glorification/dehumanization'}, {'name': 'Abusive + Person-directed', 'num_labels': 4, 'description': 'derogation/animosity/threatening/glorification/dehumanization'}, {'name': 'Abusive + Affiliation directed', 'num_labels': 1, 'description': 'abuse to them/abuse about them'}, {'name': 'Counter Speech', 'num_labels': 3, 'description': 'against identity-directed abuse/against affiliation-directed abuse/against person-directed abuse'}, {'name': 'Non-hateful Slurs and Neutral', 'num_labels': 1, 'description': ''}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/41.md\n",
      "[{'name': 'Hate Speech and Offensive Language', 'language': 'English', 'url': 'https://github.com/t-davidson/hate-speech-and-offensive-language', 'labels': [{'name': 'Hate', 'num_labels': 1, 'description': 'Hate per se'}, {'name': 'Offensive', 'num_labels': 1, 'description': 'Offensive language'}, {'name': 'Neither', 'num_labels': 1, 'description': 'Neither hate nor offensive'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/42.md\n",
      "[{'name': 'Hate Speech Dataset from a White Supremacy Forum', 'language': 'English', 'url': 'https://github.com/Vicomtech/hate-speech-dataset', 'labels': [{'name': 'Hate', 'num_labels': 1, 'description': 'Hate per se'}, {'name': 'Relation', 'num_labels': 1, 'description': 'Relation'}, {'name': 'Not', 'num_labels': 1, 'description': 'Not'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/43.md\n",
      "[{'name': 'Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter', 'language': 'English', 'url': 'https://github.com/ZeerakW/hatespeech', 'labels': [{'name': 'Sexist', 'num_labels': 1, 'description': 'Racism'}, {'name': 'Racist', 'num_labels': 1, 'description': 'Sexism'}, {'name': 'Not', 'num_labels': 1, 'description': ''}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/44.md\n",
      "[{'name': 'fox-news-comments', 'language': 'English', 'url': 'https://github.com/sjtuprog/fox-news-comments', 'labels': [{'name': 'Hate', 'num_labels': 1, 'description': 'Hate per se'}, {'name': 'Not Hate', 'num_labels': 1, 'description': 'Not hate'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/45.md\n",
      "[{'name': 'The Gab Hate Corpus', 'language': 'English', 'url': 'https://osf.io/edua3/', 'labels': [{'name': 'Hate vs. Offensive/Vulgarity', 'num_labels': 2, 'description': 'Binary classification task to identify hate speech vs. offensive/vulgar content'}, {'name': 'Assault on human Dignity/Call for Violence', 'num_labels': 2, 'description': 'Binary classification task to identify assault on human dignity/call for violence'}, {'name': 'Identity based hate', 'num_labels': 8, 'description': 'Multinomial classification task to identify identity-based hate (race/ethnicity, nationality/regionalism/xenophobia, gender, religion/belief system, sexual orientation, ideology, political identification/party, mental/physical health)'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/46.md\n",
      "[{'name': 'Are You a Racist or Am I Seeing Things? Annotator Influence on Hate Speech Detection on Twitter', 'language': 'English', 'url': 'https://github.com/ZeerakW/hatespeech', 'labels': [{'name': 'Sexist', 'num_labels': 1, 'description': 'Sexism'}, {'name': 'Racist', 'num_labels': 1, 'description': 'Racism'}, {'name': 'Neither', 'num_labels': 1, 'description': ''}, {'name': 'Both', 'num_labels': 1, 'description': ''}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/47.md\n",
      "[{'name': 'When Does a Compliment Become Sexist? Analysis and Classification of Ambivalent Sexism Using Twitter Data', 'language': 'English', 'url': 'https://github.com/AkshitaJha/NLP_CSS_2017', 'labels': [{'name': 'Hierarchy of Sexism', 'num_labels': 3, 'description': 'Benevolent sexism, Hostile sexism, None'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/48.md\n",
      "[{'name': 'Automatic Misogyny Identification at IberEval 2018', 'language': 'English', 'url': 'https://amiibereval2018.wordpress.com/important-dates/data/', 'labels': [{'name': 'misogyny', 'num_labels': 2, 'description': 'Binary classification (misogyny / not)'}, {'name': 'stereotype', 'num_labels': 5, 'description': '5 categories (stereotype, dominance, derailing, sexual harassment, discredit)'}, {'name': 'target_of_misogyny', 'num_labels': 2, 'description': 'Active or passive'}], 'relevant': 'yes'}]\n",
      "___\n",
      "tmp-markdown/49.md\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_path \u001b[38;5;129;01min\u001b[39;00m data_paths:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data_path)\n\u001b[0;32m---> 52\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkdown_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(datasets)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m___\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 38\u001b[0m, in \u001b[0;36mDatasetAgent.__call__\u001b[0;34m(self, markdown_file_path)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, markdown_file_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkdown_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarkdown_file_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/src/generate.py:17\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(system_prompt, prompt, model, schema, parse, num_ctx, num_predict, temperature)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m      8\u001b[0m     system_prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m      9\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     temperature: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     16\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     response: ChatResponse \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_ctx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_predict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_predict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# this is not needed when temp is 0\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepeat_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# remain default for json outputs, from experience.\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     res \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse \u001b[38;5;129;01mand\u001b[39;00m schema:\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/ollama/_client.py:333\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    290\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    291\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/ollama/_client.py:178\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/ollama/_client.py:118\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/git/open-source/books/toffellm/venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pydantic.json_schema import GenerateJsonSchema, JsonSchemaValue\n",
    "from typing import Literal\n",
    "\n",
    "LANGUAGE = \"English\"\n",
    "\n",
    "\n",
    "class DatasetAgent(Agent):\n",
    "    def system(self):\n",
    "        return \"You are a helpful assistant that retrieves relevant information about datasets in a specific topic.\"\n",
    "\n",
    "    def prompt(self, markdown_file_path):\n",
    "        data = None\n",
    "        with open(markdown_file_path) as f:\n",
    "            data = f.read()\n",
    "        if not data:\n",
    "            return \"No data provided.\"\n",
    "        return f\"From the provided information:\\n{data}\\nFind details about specific datasets (in {LANGUAGE} preferably), including information about its language, links, and labels. Determine if the dataset is relevant to the topic of {TOPIC} and is in the {LANGUAGE} language, specified by the 'relevant' field. Output in JSON.\"\n",
    "\n",
    "    def schema(self):\n",
    "        class DatasetLabel(BaseModel):\n",
    "            name: str\n",
    "            num_labels: int\n",
    "            description: str\n",
    "\n",
    "        class DatasetSchema(BaseModel):\n",
    "            name: str\n",
    "            language: str\n",
    "            url: str\n",
    "            labels: List[DatasetLabel]\n",
    "            relevant: Literal[\"yes\", \"no\"]\n",
    "\n",
    "        class DatasetFinderSchema(BaseModel):\n",
    "            datasets: List[DatasetSchema]\n",
    "\n",
    "        return DatasetFinderSchema.model_json_schema()\n",
    "\n",
    "    def __call__(self, markdown_file_path: str):\n",
    "        return generate(\n",
    "            system_prompt=self.system(),\n",
    "            prompt=self.prompt(markdown_file_path=markdown_file_path),\n",
    "            schema=self.schema(),\n",
    "            model=model,\n",
    "            num_ctx=4096,\n",
    "            temperature=0.1,\n",
    "        )[\"datasets\"]\n",
    "\n",
    "dataset_agent = DatasetAgent()\n",
    "\n",
    "data_paths = [f\"{TMP_FOLDER}/{i}.md\" for i in range(len(hashed_results))]\n",
    "for data_path in data_paths:\n",
    "    print(data_path)\n",
    "    datasets = dataset_agent(markdown_file_path=data_path)\n",
    "    print(datasets)\n",
    "    print(\"___\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}